{
 "cells": [
  {
   "cell_type": "code",
   "id": "ec5ac3f4-1466-47ba-b83a-a515fba3a9dd",
   "metadata": {
    "include-cell-in-app": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "# Electricity Demand Forecasting\n",
    "\n",
    "This Jupyter Notebook provides a comprehensive analysis and forecasting of monthly electricity consumption.\n",
    "The goal is to forecast electricity demand for the next 1-2 years using various time series models,\n",
    "evaluate their performance, and select the best model for future demand estimation.\n",
    "\n",
    "## Data Description\n",
    "The dataset `Electricity Consumption.csv` contains:\n",
    "- `DATE`: Month and Year (e.g., 1/1/1973)\n",
    "- `Electricty_Consumption_in_TW`: Electricity consumption in Trillion Watts\n",
    "\n",
    "## Objectives\n",
    "1.  **Data Preprocessing:** Clean and prepare the time series data.\n",
    "2.  **Model Comparison:** Implement and compare:\n",
    "    -   Decomposition Model\n",
    "    -   Exponential Smoothing (Holt-Winters) Model\n",
    "    -   SARIMA Model\n",
    "3.  **Error Metrics Calculation:** Compute RMSE, RMSPE, and MAPE for model validation.\n",
    "4.  **Demand Estimation:** Provide monthly demand forecasts for the next 1-2 years.\n",
    "5.  **Model Selection:** Justify the choice of the best-performing model.\n",
    "6.  **Visualization:** Plot historical data and forecasts.\n",
    "\"\"\"\n",
    "\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## 1. Import Libraries and Load Data\n",
    "First, we import all necessary libraries and load the `Electricity Consumption.csv` file into a pandas DataFrame.\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing # Using ExponentialSmoothing for ETS-like functionality\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output, especially from model convergence\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the dataset\n",
    "# Make sure 'Electricity Consumption.csv' is in the same directory as this notebook\n",
    "try:\n",
    "    df = pd.read_csv(r\"C:\\Users\\DELL\\OneDrive\\Desktop\\assignment\\Electricity Consumption.csv\")\n",
    "    print(\"Data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'Electricity Consumption.csv' not found. Please ensure the file is in the correct directory.\")\n",
    "    # Exit or handle the error appropriately if the file is crucial\n",
    "    exit()\n",
    "\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## 2. Data Preprocessing\n",
    "We will convert the 'DATE' column to datetime objects and set it as the DataFrame index.\n",
    "We also rename the consumption column for easier access.\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "# Convert 'DATE' column to datetime objects\n",
    "df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "\n",
    "# Set 'DATE' as the DataFrame index\n",
    "df.set_index('DATE', inplace=True)\n",
    "\n",
    "# Rename the electricity consumption column for clarity\n",
    "df.rename(columns={'Electricty_Consumption_in_TW': 'Electricity Consumption'}, inplace=True)\n",
    "\n",
    "# Display the first few rows and information about the DataFrame\n",
    "print(\"DataFrame after preprocessing:\")\n",
    "print(df.head())\n",
    "print(\"\\nDataFrame Info:\")\n",
    "df.info()\n",
    "\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## 3. Split Data into Training and Testing Sets\n",
    "To evaluate model performance, we split the data into a training set (up to December 2017)\n",
    "and a testing set (January 2018 onwards). The test set will be used to validate our models\n",
    "before making future predictions.\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "# Define the end date for the training data\n",
    "train_end_date = '2017-12-01'\n",
    "\n",
    "# Split the data\n",
    "train_data = df.loc[:train_end_date]\n",
    "# The test data starts from the month immediately following the training data's last month\n",
    "test_data = df.loc[train_data.index.max() + pd.DateOffset(months=1):]\n",
    "\n",
    "print(f\"Training data period: {train_data.index.min().strftime('%Y-%m')} to {train_data.index.max().strftime('%Y-%m')}\")\n",
    "print(f\"Test data period: {test_data.index.min().strftime('%Y-%m')} to {test_data.index.max().strftime('%Y-%m')}\")\n",
    "print(f\"Number of training observations: {len(train_data)}\")\n",
    "print(f\"Number of test observations: {len(test_data)}\")\n",
    "\n",
    "# Define the forecast period for future predictions (next 1-2 years from December 2019)\n",
    "# The data ends in December 2019, so we forecast from January 2020 to December 2021.\n",
    "forecast_start_date = pd.to_datetime('2020-01-01')\n",
    "forecast_end_date = pd.to_datetime('2021-12-01')\n",
    "forecast_index = pd.date_range(start=forecast_start_date, end=forecast_end_date, freq='MS')\n",
    "\n",
    "print(f\"\\nFuture forecast period: {forecast_index.min().strftime('%Y-%m')} to {forecast_index.max().strftime('%Y-%m')}\")\n",
    "print(f\"Number of future forecast steps: {len(forecast_index)}\")\n",
    "\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## 4. Model Implementation and Evaluation\n",
    "\n",
    "We will implement three different time series forecasting models:\n",
    "1.  **Decomposition Model:** Separates the time series into trend, seasonal, and residual components.\n",
    "2.  **Exponential Smoothing (Holt-Winters) Model:** A popular method for data with trend and seasonality.\n",
    "3.  **SARIMA (Seasonal AutoRegressive Integrated Moving Average) Model:** A powerful model that handles both non-seasonal and seasonal components.\n",
    "\n",
    "For each model, we will:\n",
    "-   Train it on the `train_data`.\n",
    "-   Generate forecasts for the `test_data` period to evaluate its accuracy.\n",
    "-   Calculate RMSE, MAPE, and RMSPE as error metrics.\n",
    "-   Generate forecasts for the future `forecast_index` period.\n",
    "\"\"\"\n",
    "\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "### 4.1. Decomposition Model\n",
    "This model breaks down the time series into its constituent components: trend, seasonality, and residual.\n",
    "We then forecast these components separately and combine them. For simplicity, the trend is forecasted\n",
    "using its last known value, and seasonality is repeated.\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "# Perform additive decomposition (visually inspected to be appropriate for this data)\n",
    "decomposition = seasonal_decompose(train_data['Electricity Consumption'], model='additive', period=12)\n",
    "\n",
    "# Get the trend and seasonal components\n",
    "trend = decomposition.trend.dropna()\n",
    "seasonal = decomposition.seasonal.dropna()\n",
    "\n",
    "# Forecast trend using the last known value (simple approach)\n",
    "last_trend_value = trend.iloc[-1]\n",
    "# Get the last 12 seasonal values to repeat for future forecasts\n",
    "last_seasonal_values = seasonal[-12:]\n",
    "\n",
    "# Extend trend for the future forecast period\n",
    "trend_forecast_decomposition = pd.Series(last_trend_value, index=forecast_index)\n",
    "\n",
    "# Extend seasonal component by repeating the last year's seasonality\n",
    "seasonal_forecast_decomposition = pd.Series(\n",
    "    np.tile(last_seasonal_values, (len(forecast_index) // 12) + 1)[:len(forecast_index)],\n",
    "    index=forecast_index\n",
    ")\n",
    "\n",
    "# Combine trend and seasonal forecasts for the future period\n",
    "decomposition_forecast = trend_forecast_decomposition + seasonal_forecast_decomposition\n",
    "\n",
    "# Evaluate Decomposition Model on the test data\n",
    "# Create a specific index for the test period for decomposition forecast evaluation\n",
    "test_forecast_index_decomposition = pd.date_range(start=test_data.index.min(), end=test_data.index.max(), freq='MS')\n",
    "\n",
    "# Extend trend and seasonal components for the test period for evaluation\n",
    "trend_test_decomposition = pd.Series(last_trend_value, index=test_forecast_index_decomposition)\n",
    "seasonal_test_decomposition = pd.Series(\n",
    "    np.tile(last_seasonal_values, (len(test_forecast_index_decomposition) // 12) + 1)[:len(test_forecast_index_decomposition)],\n",
    "    index=test_forecast_index_decomposition\n",
    ")\n",
    "test_decomposition_forecast_values = trend_test_decomposition + seasonal_test_decomposition\n",
    "\n",
    "# Calculate error metrics for Decomposition Model\n",
    "rmse_decomposition = np.sqrt(mean_squared_error(test_data['Electricity Consumption'], test_decomposition_forecast_values))\n",
    "mape_decomposition = mean_absolute_percentage_error(test_data['Electricity Consumption'], test_decomposition_forecast_values) * 100\n",
    "rmspe_decomposition = np.sqrt(np.mean(np.square(((test_data['Electricity Consumption'] - test_decomposition_forecast_values) / test_data['Electricity Consumption'])))) * 100\n",
    "\n",
    "print(f\"Decomposition Model - RMSE: {rmse_decomposition:.3f}, MAPE: {mape_decomposition:.3f}%, RMSPE: {rmspe_decomposition:.3f}%\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "### 4.2. Exponential Smoothing (Holt-Winters) Model\n",
    "This model is suitable for time series with both trend and seasonality. We use an additive trend and additive seasonality.\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "# Initialize and fit the Exponential Smoothing model\n",
    "# seasonal_periods=12 for monthly data\n",
    "# trend='add' and seasonal='add' are chosen based on visual inspection of the data\n",
    "exp_smoothing_model = ExponentialSmoothing(train_data['Electricity Consumption'],\n",
    "                                          seasonal_periods=12,\n",
    "                                          trend='add',\n",
    "                                          seasonal='add',\n",
    "                                          initialization_method=\"estimated\")\n",
    "exp_smoothing_fit = exp_smoothing_model.fit()\n",
    "\n",
    "# Generate future forecasts\n",
    "exp_smoothing_forecast = exp_smoothing_fit.forecast(steps=len(forecast_index))\n",
    "exp_smoothing_forecast.index = forecast_index\n",
    "\n",
    "# Evaluate Exponential Smoothing Model on the test data\n",
    "exp_smoothing_test_forecast = exp_smoothing_fit.forecast(steps=len(test_data))\n",
    "exp_smoothing_test_forecast.index = test_data.index\n",
    "\n",
    "# Calculate error metrics for Exponential Smoothing Model\n",
    "rmse_exp_smoothing = np.sqrt(mean_squared_error(test_data['Electricity Consumption'], exp_smoothing_test_forecast))\n",
    "mape_exp_smoothing = mean_absolute_percentage_error(test_data['Electricity Consumption'], exp_smoothing_test_forecast) * 100\n",
    "rmspe_exp_smoothing = np.sqrt(np.mean(np.square(((test_data['Electricity Consumption'] - exp_smoothing_test_forecast) / test_data['Electricity Consumption'])))) * 100\n",
    "\n",
    "print(f\"Exponential Smoothing Model - RMSE: {rmse_exp_smoothing:.3f}, MAPE: {mape_exp_smoothing:.3f}%, RMSPE: {rmspe_exp_smoothing:.3f}%\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "### 4.3. SARIMA Model\n",
    "SARIMA models are highly flexible and can capture complex patterns. We use a commonly effective order\n",
    "for monthly data: `(1,1,1)` for the non-seasonal part and `(1,1,0,12)` for the seasonal part.\n",
    "Optimal parameters can be found using `pmdarima.auto_arima` for real-world applications.\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "# Define SARIMA orders (p,d,q) and seasonal orders (P,D,Q,s)\n",
    "# (1,1,1) for non-seasonal: AR(1), I(1) - one differencing, MA(1)\n",
    "# (1,1,0,12) for seasonal: Seasonal AR(1), Seasonal I(1) - one seasonal differencing, Seasonal MA(0), Period=12 (monthly)\n",
    "sarima_order = (1, 1, 1)\n",
    "sarima_seasonal_order = (1, 1, 0, 12)\n",
    "\n",
    "# Initialize and fit the SARIMA model\n",
    "sarima_model = SARIMAX(train_data['Electricity Consumption'],\n",
    "                       order=sarima_order,\n",
    "                       seasonal_order=sarima_seasonal_order,\n",
    "                       enforce_stationarity=False, # Set to False to allow non-stationary models if needed\n",
    "                       enforce_invertibility=False) # Set to False for robustness\n",
    "sarima_fit = sarima_model.fit(disp=False) # disp=False to suppress optimization messages\n",
    "\n",
    "# Generate future forecasts\n",
    "sarima_forecast = sarima_fit.forecast(steps=len(forecast_index))\n",
    "sarima_forecast.index = forecast_index\n",
    "\n",
    "# Evaluate SARIMA Model on the test data\n",
    "sarima_test_forecast = sarima_fit.forecast(steps=len(test_data))\n",
    "sarima_test_forecast.index = test_data.index\n",
    "\n",
    "# Calculate error metrics for SARIMA Model\n",
    "rmse_sarima = np.sqrt(mean_squared_error(test_data['Electricity Consumption'], sarima_test_forecast))\n",
    "mape_sarima = mean_absolute_percentage_error(test_data['Electricity Consumption'], sarima_test_forecast) * 100\n",
    "rmspe_sarima = np.sqrt(np.mean(np.square(((test_data['Electricity Consumption'] - sarima_test_forecast) / test_data['Electricity Consumption'])))) * 100\n",
    "\n",
    "print(f\"SARIMA Model - RMSE: {rmse_sarima:.3f}, MAPE: {mape_sarima:.3f}%, RMSPE: {rmspe_sarima:.3f}%\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## 5. Compare Models and Select the Best\n",
    "\n",
    "We compile the error metrics from all models and identify the one with the lowest RMSE.\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "# Create a DataFrame to compare error metrics\n",
    "metrics = {\n",
    "    'Model': ['Decomposition', 'Exponential Smoothing', 'SARIMA'],\n",
    "    'RMSE': [rmse_decomposition, rmse_exp_smoothing, rmse_sarima],\n",
    "    'MAPE (%)': [mape_decomposition, mape_exp_smoothing, mape_sarima],\n",
    "    'RMSPE (%)': [rmspe_decomposition, rmspe_exp_smoothing, rmspe_sarima]\n",
    "}\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "print(\"Error Metrics for Each Model:\")\n",
    "print(metrics_df.to_markdown(index=False))\n",
    "\n",
    "# Select the best model based on the lowest RMSE\n",
    "best_model_name = metrics_df.loc[metrics_df['RMSE'].idxmin()]['Model']\n",
    "print(f\"\\nSelected Model: {best_model_name}\")\n",
    "\n",
    "# Assign the forecast from the best model to a variable\n",
    "best_forecast = None\n",
    "if best_model_name == 'Decomposition':\n",
    "    best_forecast = decomposition_forecast\n",
    "elif best_model_name == 'Exponential Smoothing':\n",
    "    best_forecast = exp_smoothing_forecast\n",
    "elif best_model_name == 'SARIMA':\n",
    "    best_forecast = sarima_forecast\n",
    "\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## 6. Demand Estimation for Next 1-2 Years\n",
    "\n",
    "Here are the monthly electricity demand estimations for the next 1-2 years (January 2020 to December 2021)\n",
    "using the selected best model.\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "print(\"\\nDemand Estimation for next 1-2 years (monthly basis):\")\n",
    "print(best_forecast.to_markdown(numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "print(f\"\\nReason for selection: The {best_model_name} model exhibited the lowest RMSE (Root Mean Squared Error) among the evaluated models, indicating that its predictions are closest to the actual values on average.\")\n",
    "\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## 7. Visualization of Forecasts\n",
    "\n",
    "Finally, we plot the historical data, actual test data, and the forecasts from all models\n",
    "to visually inspect their performance and the projected demand.\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(train_data.index, train_data['Electricity Consumption'], label='Training Data', color='blue')\n",
    "plt.plot(test_data.index, test_data['Electricity Consumption'], label='Actual Test Data', color='orange')\n",
    "plt.plot(decomposition_forecast.index, decomposition_forecast, label='Decomposition Forecast', linestyle='--', color='green')\n",
    "plt.plot(exp_smoothing_forecast.index, exp_smoothing_forecast, label='Exponential Smoothing Forecast', linestyle='-.', color='red')\n",
    "plt.plot(sarima_forecast.index, sarima_forecast, label='SARIMA Forecast', linestyle=':', color='purple')\n",
    "\n",
    "plt.title('Electricity Consumption Forecast (1-2 Years)', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Electricity Consumption (Trillion Watts)', fontsize=12)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %%"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "70512a7c-61e2-4f50-b8f7-64c73c4df224",
   "metadata": {
    "include-cell-in-app": true
   },
   "source": [
    "Electricity Demand Forecasting Result Report\n",
    "1. Introduction\n",
    "This report details the process and outcomes of forecasting monthly electricity consumption for the next 1-2 years (January 2020 to December 2021), based on historical data from January 1973 to December 2019. The primary objective is to provide actionable insights for managing electricity production by accurately predicting future demand.\n",
    "\n",
    "2. Methodology\n",
    "The forecasting process involved the following key steps:\n",
    "\n",
    "2.1. Data Preprocessing\n",
    "The provided Electricity Consumption.csv dataset was loaded. The 'DATE' column was converted to datetime objects and set as the DataFrame's index. The 'Electricty_Consumption_in_TW' column was renamed to 'Electricity Consumption' for clarity.\n",
    "\n",
    "2.2. Data Splitting\n",
    "The historical data was split into training and testing sets to enable robust model validation.\n",
    "\n",
    "Training Data: January 1973 to December 2017.\n",
    "\n",
    "Testing Data: January 2018 to December 2019.\n",
    "This split allowed us to evaluate how well each model generalized to unseen data before making future predictions.\n",
    "\n",
    "2.3. Model Selection and Implementation\n",
    "Three different time series forecasting models were implemented and compared:\n",
    "\n",
    "Decomposition Model: This approach involves decomposing the time series into its underlying components: trend, seasonality, and residuals. The forecast is then generated by extending the trend (using the last known value) and repeating the seasonal pattern. An additive model was used based on the visual characteristics of the data.\n",
    "\n",
    "Exponential Smoothing (Holt-Winters) Model: This model is well-suited for time series exhibiting both trend and seasonality. An additive trend and additive seasonality were specified, with a seasonal period of 12 (due to monthly data).\n",
    "\n",
    "SARIMA (Seasonal AutoRegressive Integrated Moving Average) Model: A powerful and flexible model capable of capturing complex non-seasonal and seasonal dependencies. The model orders used were (1,1,1) for the non-seasonal part (AR, I, MA) and (1,1,0,12) for the seasonal part (Seasonal AR, Seasonal I, Seasonal MA, Seasonal Period).\n",
    "\n",
    "2.4. Error Metrics\n",
    "The performance of each model was evaluated using the following error metrics on the test set:\n",
    "\n",
    "RMSE (Root Mean Squared Error): Measures the average magnitude of the errors. It is sensitive to large errors.\n",
    "\n",
    "MAPE (Mean Absolute Percentage Error): Expresses the accuracy as a percentage of the error. It is scale-independent and easy to interpret.\n",
    "\n",
    "RMSPE (Root Mean Squared Percentage Error): Similar to MAPE but penalizes larger errors more heavily due to squaring.\n",
    "\n",
    "3. Results and Model Comparison\n",
    "The error metrics calculated for each model on the test data are as follows:\n",
    "\n",
    "Model\n",
    "\n",
    "RMSE\n",
    "\n",
    "MAPE (%)\n",
    "\n",
    "RMSPE (%)\n",
    "\n",
    "Decomposition\n",
    "\n",
    "5.392\n",
    "\n",
    "4.419\n",
    "\n",
    "5.073\n",
    "\n",
    "Exponential Smoothing\n",
    "\n",
    "3.549\n",
    "\n",
    "2.566\n",
    "\n",
    "3.666\n",
    "\n",
    "SARIMA\n",
    "\n",
    "3.671\n",
    "\n",
    "2.570\n",
    "\n",
    "3.711\n",
    "\n",
    "4. Selected Model and Justification\n",
    "Based on the evaluation metrics, the Exponential Smoothing (Holt-Winters) Model was selected as the best-performing model for forecasting electricity demand.\n",
    "\n",
    "Reason for Selection:\n",
    "The Exponential Smoothing model exhibited the lowest RMSE (3.549) among all evaluated models. A lower RMSE indicates that the model's predictions are, on average, closer to the actual values, signifying higher accuracy and better fit to the underlying patterns in the electricity consumption data. While MAPE and RMSPE were also competitive, RMSE served as the primary selection criterion for its direct measure of prediction error magnitude.\n",
    "\n",
    "5. Demand Estimation for Next 1-2 Years\n",
    "Using the selected Exponential Smoothing model, the monthly electricity demand for the next 1-2 years (January 2020 to December 2021) is estimated as follows:\n",
    "\n",
    "Date\n",
    "\n",
    "Electricity Consumption (Trillion Watts)\n",
    "\n",
    "2020-01-01\n",
    "\n",
    "109.106\n",
    "\n",
    "2020-02-01\n",
    "\n",
    "102.298\n",
    "\n",
    "2020-03-01\n",
    "\n",
    "95.507\n",
    "\n",
    "2020-04-01\n",
    "\n",
    "89.625\n",
    "\n",
    "2020-05-01\n",
    "\n",
    "94.756\n",
    "\n",
    "2020-06-01\n",
    "\n",
    "109.989\n",
    "\n",
    "2020-07-01\n",
    "\n",
    "120.495\n",
    "\n",
    "2020-08-01\n",
    "\n",
    "120.016\n",
    "\n",
    "2020-09-01\n",
    "\n",
    "107.418\n",
    "\n",
    "2020-10-01\n",
    "\n",
    "94.241\n",
    "\n",
    "2020-11-01\n",
    "\n",
    "92.707\n",
    "\n",
    "2020-12-01\n",
    "\n",
    "102.681\n",
    "\n",
    "2021-01-01\n",
    "\n",
    "110.611\n",
    "\n",
    "2021-02-01\n",
    "\n",
    "103.802\n",
    "\n",
    "2021-03-01\n",
    "\n",
    "97.011\n",
    "\n",
    "2021-04-01\n",
    "\n",
    "91.129\n",
    "\n",
    "2021-05-01\n",
    "\n",
    "96.261\n",
    "\n",
    "2021-06-01\n",
    "\n",
    "111.494\n",
    "\n",
    "2021-07-01\n",
    "\n",
    "122.000\n",
    "\n",
    "2021-08-01\n",
    "\n",
    "121.521\n",
    "\n",
    "2021-09-01\n",
    "\n",
    "108.923\n",
    "\n",
    "2021-10-01\n",
    "\n",
    "95.746\n",
    "\n",
    "2021-11-01\n",
    "\n",
    "94.212\n",
    "\n",
    "2021-12-01\n",
    "\n",
    "104.185\n",
    "\n",
    "6. Conclusion\n",
    "The Exponential Smoothing model provides reliable monthly forecasts for electricity demand for the next two years. These estimations can be valuable for strategic planning, resource allocation, and operational management of electricity production to meet anticipated demand. Further refinements could include incorporating external factors (e.g., temperature, economic indicators) and exploring more advanced models or ensemble methods for even greater accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f72f61f-0d85-4e8e-9538-d19c2dc4d773",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
